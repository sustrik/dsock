<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd">

<rfc category="info" docName="sock-api-revamp-01">

  <front>

    <title abbrev="BSD Socket API Revamp">
    BSD Socket API Revamp
    </title>

    <author fullname="Martin Sustrik" initials="M." surname="Sustrik" role="editor">
      <address>
        <email>sustrik@250bpm.com</email>
      </address>
    </author>

    <date month="February" year="2017" />

    <area>Applications</area>
    <workgroup>Internet Engineering Task Force</workgroup>

    <keyword>BSD sockets</keyword>
    <keyword>API</keyword>

    <abstract>
      <t>This memo describes new API for network sockets. Compared to classic
         BSD socket API the new API is much more lightweight and flexible.
         Its primary focus is on easy composability of network protocols.</t>
    </abstract>

  </front>

  <middle>

    <section title = "Introduction">
      <t>The progress in the area of network protocols is distinctively
         lagging behind. While every hobbyist writes and publishes their small
         JavaScript libraries, there's no such thing going on with network
         protocols. Indeed, it looks like the field of network protocols is
         dominated by big companies and academia, just like programming as a
         whole used to be before the advent of personal computers.</t>
      <t>While social and political reasons may be partly to blame (adoption,
         interoperability etc.) the technology itself creates a huge barrier
         to popular participation. For example, the fact that huge part of the
         networking stack typically lives in the kernel space will prevent most
         people from even trying. More importantly though there is basically
         no way to reuse what already exists. While in JavaScript world you can
         get other people's libraries, quickly glue them together, add a bit of
         code of your own and publish a shiny new library, you can't do the same
         thing with network protocols. You can't take framing from WebSockets,
         add multihoming from SCTP, keep-alives from TCP and congestion control
         from DCCP. You have to write most of the code yourself which requires
         a lot of time, often more than a single hobbyist programmer can
         realistically afford.</t>
      <t>This memo proposes to fix the reusability problem by revamping the
         old BSD socket API and while doing so strongly focusing on
         composability of protocols.</t>
    </section>

    <section title="Terminology">
      <t>The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT",
         "SHOULD", "SHOULD NOT", "RECOMMENDED",  "MAY", and "OPTIONAL" in this
         document are to be interpreted as described in RFC 2119.</t>
    </section>

    <section title="The problems">
      <t>This section offers a brief summary of the problems that protocol
         implementors are facing in the current environment.
         <list style="symbols">
           <t>The hook-in API to implement new protocols and make them
              accessible via standard functions like send() and recv() exists,
              in most cases, only in the kernel space. While that makes
              implementation a little bit harder the real problem is deployment.
              Kernel is rarely deployed with the application and waiting for a
              kernel patch to be widely deployed can take many years.</t>
           <t>The API hook-in API is not standardized meaning that a protocol
              has to be implemented for each operating system separately.</t>
           <t>The usability of the original blocking BSD socket API is dependent
              one operating system's ability to spawn a lot of threads (e.g. two
              per TCP connection) and switch between them quickly. This happens
              not to be the case with majority of operating systems. The thread
              number limit tends to be couple of thousand and the
              context switch latency is often one or two orders of magnitude
              higher than what would be acceptable for high-performance
              networking. This leads to proliferation of asynchronous network
              code using non-blocking APIs like poll() which forces
              the implementor to do both CPU and network scheduling by hand.
              High context switch latency is often fought by extreme measures.
              For example, by implementing hand-crafted lock-free algorithms.
              Ugly, mislayered and barely maintainable code ensues.</t>
           <t>The BSD socket API is semantically underspecified. The particular
              points of pain are error handling and behaviour during protocol
              shutdown. No fixed semantics to rely on means that higher level
              protocols are fine-tuned to work with a particular low level
              protocol (e.g. TCP) and don't allow to switch it for a different
              low-level protocol. The situation is made worse by
              offering a high number of socket options that modify semantics
              of the core APIs.</t>
           <t>Scope of BSD socket API is unnecessarily wide. It attempts to
              provide standardized way for doing things that would better be
              done in a customized way. This results in unnecessarily complex
              system of extension points: Socket options, ancillary data,
              fcntl(), various arguments to socket() function.</t>
           <t>Finally, there are some minor ways to improve the socket API
              which, however, are not a sufficient reason to revamp the API.
              But if the revamp is to be done anyway these minor issues can
              be fixed.</t>
         </list>
      </t>
    </section>

    <section title="Basic concepts">

      <section title="Vertical composability">
        <t>Vertical composability is an ability to stack protocols one on the
           top of another. From the network point of view the protocol on the
           top is a payload of the protocol on the bottom. From the API point of
           view the top protocol encapsulates the bottom protocol, very much
           like a function encapsulates another function that it calls.</t>
        <t>Example of vertical stack of protocols:</t>
        <figure>
          <artwork>
                            +----------+
                            |   HTTP   | 
                            +----------+
                            |    TCP   |
                            +----------+
                            |    IP    |
                            +----------+
                            | Ethernet |
                            +----------+
          </artwork>
        </figure>
      </section>

      <section title="Horizontal composability">
        <t>Horizontal composability is an ability to execute protocols in
           sequential manner. From the network point of view one type of
           communication ends and is replaced by another type of communication.
           From API point of view one protocol is terminated and another one
           is started, reusing the same underlying protocol, very much like
           a function can call two child functions in sequence without
           having to exit itself.</t>
        <t>An example of horizontal composability is how typical web page is
           trasferred by first doing HTTP handshake, followed by HTML body:</t>
        <figure>
          <artwork>
               +-----------------------------------+
               |   HTTP   |          HTML          |
               +----------+------------------------+
               |                TCP                |
               +-----------------------------------+
          </artwork>
        </figure>
        <t>Note how this design makes protocol reusable: The same HTTP handshake
           can be used, for example, to initiate a WebSocket session.</t>
        <t>Another example of horizontal composability is how STARTTLS switches
           non-encrypted protocol into encrypted version of the same protocol.
           </t>
        <t>While these are very visible cases of composing protocols
           horizontally, the technique is in fact ubiquitous. For example,
           most protocols are composed from three distinct mini-protocols:
           protocol header (initial handshake), protocol body (sending data
           back and forth) and protocol footer (terminal handshake):</t>
        <figure>
          <artwork>
               +-----------------------------------+
               | Header |       Body      | Footer |
               +--------+-----------------+--------+
               |                TCP                |
               +-----------------------------------+
          </artwork>
        </figure>
      </section>

      <section title="Application and transport protocols">
        <section title = "Application protocols">
           <t>Application protocols live on the top of the network stack. Rather
              than trasferring raw data they are meant to perform a specific
              service for the user. For example, DNS protocol provides name
              resolution service.</t>
           <t>Application protocols don't give user a way to send or receive
              data. They have no standardized API for sending or receiving.
              Still, they can be initialized, terminated and layered on top
              of other protocols. That being the case, relevant parts of
              this specification still apply to them.</t>
        </section>
        <section title = "Presentation protocols">
           <t>Presentation protocols add structure to data carried by transport
              protocols (e.g. ASN.1, JSON, XML). This proposal doesn't address
              them in any way. Either the protocol sends and receives binary
              data that just happen to be in a structured format in which case
              it's a standard transport protocol. Or the protocol exposes
              special API to browse the structured data in which case it should
              be treated as an application protocol.</t>
        </section>
        <section title = "Transport protocols">
           <t>The term "transport protocol" in this memo has broader scope than
              "OSI L4 protocol". By "transport protocol" we mean anything
              capable of sending and/or receiving unstructured data, be it TCP,
              IP or Ethernet.</t>
        </section>
      </section>

      <section title="Bytestream and message protocols">
        <t>Byte stream protocols are transport protocols that define no
           message boundaries. One peer can send 10 bytes, then 8 bytes. The
           other peer can read all 18 bytes at once or read 12 bytes first,
           6 bytes second. Bytestream protocols are always reliable (no bytes
           can be lost) and ordered (bytes are received in the same order they
           were sent in). TCP is a classic example of bytestream protocol.</t>
        <t>Message protocols are transport protocols that preserve message
           boundaries. While message protocols are not necessarily reliable
           (messages can be lost) or ordered (messages can be received in
           different order than they were sent in) they are always atomic.
           User will receive either complete message or no message. IP, UDP
           and WebSockets are examples of message protocols.</t>
        <t>This memo proposes distinct API for bytestream and message protocols.
           The reason for the design decision is that while the API for the
           two is superficially similar there is large difference in
           semantics, especially when it comes to atomicity and error handling.
           </t>
        <t>As an added benefit, the fact that bytestream protocols are always
           ordered and reliable means that bytestream API provides stronger
           semantic guarantees than message API.</t>
        <t>In theory, the two API could have been unified by treating each byte
           in a bytestream protocol as a separate message. In practice, however,
           such API design would prevent batching and would thus result in
           implementations with inferior throughput characteristics.</t>
      </section>

      <section title="Connected and unconnected protocols">
        <t>From the API point of view the most significant difference between
           connected protocols such as TCP and unconnected protocols such as UDP
           is that the former have initialization and termination handshakes
           while the latter do not.</t>
        <t>This distinction turns out to be critical when contemplating
           composable microprotocols. If there are 10 connected microprotocols
           in the stack and RTT between two endpoints is 100 ms, connection
           establishment will require at least 10 roundtrips, i.e. one second or
           more.</t>
        <t>Latency of this magnitude is often not acceptable. Even worse, given
           that RTT is limited by the speed of light, it's not going to get
           better as technology advances.</t>
        <t>Therefore, the only way to get microprotocols with decent performance
           is to make majority of them unconnected. In the ideal case there
           should be at most one connected protocol in any networking stack.</t>
        <t>To achieve the goal we'll have to turn even protocols that
           instinctively feel like connected into unconnected ones.</t>
        <t>Consider a simple keep-alive protocol. The peers have to agree on a
           keep-alive interval and thus the intial handshake seems unavoidable.
           However, if the peers have agreed on the keep-alive interval
           beforehand they can just pass the number to the API and no initial
           handshake is required. We can suddenly think of the protocol as
           unconnected.</t>
        <t>Technically, the users could have just met personally and decided on
           keep-alive interval. However, it doesn't have to be that way. In most
           cases there's a connected protocol in the stack somewhere beneath the
           keep-alive protocol. If that connected protocol allows to bundle
           arbitrary data with its initial handshake we can use it to exchange
           keep-alive intervals between the peers. Later on, when instantiating
           the keep-alive protocol we can pass in the correct number via API.
           </t>
        <t>As for the terminal handshakes, these are critical for horizontal
           composability of protocols. To be able to start new protocol on
           pre-existing connection the old protocol has to be terminated and
           both peers have to agree on where exactly it have ended. To do that
           handshake is needed.</t>
        <t>Assuming there's a connected protocol beneath the user can tear down
           all the unconnected protocol layers above. Then they can shut down
           the connected protocol which will put both peers in sync with respect
           to where exaclty have the protocol ended. Afterwards they can open
           new protocols on top of the remaining layers of the stack.</t>
        <t>Each protocol MUST be either connected or unconnected. A protocol
           MUST NOT try to support both scenarios.</t>
      </section>

      <section title="Scheduling or rather lack of it">
        <t>During the decades since BSD sockets were first introduced the way
           they are used have changed significantly. While in the beginning the
           user was supposed to fork a new process for each connection and do
           all the work using simple blocking calls nowadays they are expected
           to keep a pool of connections, check them via functions like poll()
           or kqueue() and dispatch any work to be done to one of the worker
           threads in a thread pool. In other words, user is supposed to do both
           network and CPU scheduling.</t>
        <t>This change happened for performance reasons and haven't improved
           functionality or usability of BSD socket API in any way. On the
           contrary, by requiring every programmer to do system programmer's
           work it contributed to proliferation of buggy, hard-to-debug and
           barely maintainable network code.</t>
        <t>To address this problem, this memo assumes that there already exists
           an efficient concurrency implementation where forking a new
           lightweight process takes at most hundreds of nanoseconds and context
           switch takes tens of nanoseconds. Note that there are already such
           concurrency systems deployed in the wild. One well-known example are
           Golang's goroutines but there are others available as well.</t>
        <t>In such environment network programming can be done in the old
           "one process per connection" way, with all the functions exhibiting
           blocking behavior. There's no need for polling, thread pools,
           callbacks, explicit state machines or similar. </t>
        <t>This memo thus adheres to "let system programmers do system
           programming" maxim and doesn't address the problem of scheduling,
           be it CPU scheduling or network scheduling, at all.</t>
        <t>As a footnote, it should be metioned that this proposal makes couple
           of deliberate design choices that prevent the modern "schedule by
           hand" style of network programming.</t>
      </section>

      <section title="Tx buffering">
        <t>Buffering of outbound data and sending them down the stack in batches
           often results in improved performance. It is perfectly acceptable for
           protocol implementation to do so as long as data is flushed when
           the socket is closed. The data should also be flushed periodically
           not to induce unbounded latencies when there are no new outbound data
           to fill in the buffer.</t>
      </section>

      <section title="Rx buffering">
        <t>Buffering of inbound data collides with vertical composability of
           protocols.</t>
        <t>If protocol reads 1000 bytes of data from the underlying protocol,
           then protocol above it asks for 700 bytes and closes the socket,
           there's no way to push the remaining 300 bytes back to the
           underlying socket. Allowing for such operation would mean that
           the buffer of the underlying socket would have to be virtually
           unbounded.</t>
        <t>If, on the other hand, the remaining bytes were dropped there would
           be no way to start a new protocol on top of the same underlying
           socket. The new protocol would miss initial 300 bytes of data.</t>
        <t>Luckily though, the above reasoning doesn't apply to the bottommost
           protocol in the stack. Given that there's no underlying protocol to
           start a new protocol on top of, the buffered data can be simply
           dropped.</t>
        <t>Also, rx buffering on the lowermost level, where the protocol is
           interfacing with the hardware or with user/kernel space boundary,
           is likely to provide the largest performance benefits. Absence of
           rx buffering on higher levels, where performance impact of additional
           receive operation is basically that of a function call, is not likely
           to incur huge performance penalty. And even more so given that higher
           layers of the stack are likely to be message-based and thus some
           amount of batching, proportional to the average message size, happens
           anyway.</t>  
      </section>

      <section title="Socket options">
        <t>There's no equivalent to socket options as they are known from BSD
           socket API. Any such customization of the network stack is supposed
           to be built by vertically layering the protocols.</t>
      </section>

    </section>

    <section title="The API guidelines">

      <section title="Protocol naming conventions">
        <t>Whenever possible, protocol name in the API SHOULD correspond to
           the official name of the protocol, not to the name of the protocol
           implementation. While this can lead to name clashes the assumption
           is that single application is not going to use two implementations
           of the same network protocol. This rule also provides an incentive
           to standardize protocol APIs.</t>
        <t>To make the API less tedious to use, short protocol name,
           e.g. "ws", SHOULD be preferred to the long name, e.g. "websockets".
           </t>
        <t>Given that end users prefer to create full protocol stack using a
           single function it is desirable to provide them with shrinkwrapped
           protocols aggregating many microprotocols into a coherent whole. For
           example, "websocket" protocol may be composed of TCP protocol and
           WebSocket protocol itself. Still, expert users may want to have
           access to WebSocket protocol as such, without the underlying TCP
           protocol, say, if they want to run it on top of SCTP or any other
           alternative transport. In such cases there is a naming dilemma:
           Should "websocket" name refer to the TCP+WebSocket aggregate or to
           the WebSocket alone? In these cases the implemetors SHOULD always
           prefer the former solution.</t>
      </section>

      <section title="Function naming conventions">
        <t>The function names SHOULD be in lowercase and SHOULD be composed of
           short protocol name and action name separated by underscore
           (e.g. "tcp_connect"). Of course, in languages other than C the native
           naming convention should be followed, but even then the name SHOULD
           contain both short protocol name and action name.</t>
      </section>

      <section title="File descriptors">
        <t>One of the design goals of this API is to support both kernel space
           and user space implementations. One problem with that is that
           kernel space objects are typically reffered to by file descriptors
           while POSIX provides no easy way to associate user space objects with
           file descriptors.</t>
        <t>Therefore, this specification allows user space implementations
           to use fake file descriptors (simple integers that kernel space
           knows nothing about) and does not guarantee that system functions
           will work with those descriptors.</t>
        <t>For example, you cannot count on POSIX close() function to be able to
           close a socket. Therefore, hclose() function is introduced which maps
           directly to close() in kernel-space implementations but can be
           overriden by custom implementation in a user-space implementation.
           </t>
        <t>Whenever a function acts on a file descriptor, the descriptor SHOULD
           be passed to the function as its first argument.</t>
      </section>

      <section title="Deadlines">
          <t>Unlike with BSD sockets the deadlines are points in time rather than
             intervals. This allows to use the same deadline in multiple calls
             without need for recomputing the remaining interval:</t>
          <figure>
            <artwork>
    int64_t deadline = now() + 1000;
    bsend(h, "ABC", 3, deadline);
    bsend(h, "DEF", 3, deadline);
            </artwork>
          </figure>
          <t>All possibly blocking functions MUST accept a deadline. The
             deadline SHOULD be passed to the function as its last argument.</t>
      </section>

      <section title="Protocol initialization">
        <t>A protocol SHOULD be initialized using a protocol-specific "start"
           function (e.g. "smtp_start"). If protocol runs on top of another
           protocol the file descriptor of the underlying protocol SHOULD be
           supplied as the first argument of the function. The function MAY have
           arbitrary number of additional arguments.</t>
        <t>The function SHOULD return the file descriptor of the newly created
           protocol instance. In case of error it SHOULD close the underlying
           protocol, return -1 and set errno to the appropriate error.</t>
        <t>Some protocols require more complex setup. Consider TCP's
           listen/connect/accept connection setup process. These protocols
           SHOULD use custom set of functions rather than try to shoehorn all
           the functionality into a single all-purpose "start" function.</t>
        <t>If protocol runs on top of an underlying protocol it takes ownership
           of that protocol. Using the low level protocol while it is owned by a
           higher level protocol will result in undefined behaviour. A sane way
           to implement this behaviour is to create a duplicate of the underlying
           file descriptor to be owned by the parent protocol and closing the
           original file descriptor. That way, user accidentally using a lower
           level protocol will get an EBADF error.</t>
        <t>If protocol requires an initial handshake it MUST be performed
           in this phase of the socket lifecycle.</t>
        <t>Example of creating a stack of four protocols:</t>
        <figure>
          <artwork>
    int s1 = tcp_connect("192.168.0.111:5555", -1);
    int s2 = foo_start(s1, arg1, arg2, arg3);
    int s3 = bar_start(s2);
    int s4 = baz_start(s3, arg4, arg5);
          </artwork>
        </figure>
      </section>

      <section title="Protocol termination">

        <t>There are several types of termination that will be discussed in
           following sections:
           <list style="symbols">
             <t>Forceful termination means that the user wants to shut down the
                socket abruptly without even letting the peer know. Forceful
                termination is always a non-blocking operation.</t>
             <t>Half-close termination means that outbound half of the
                connection is closed by the user and the terminal handshake, if
                supported by the protocol, is initiated. However, the user is
                still able to receive data from the peer.</t>
             <t>Orderly termination means that terminal handshake with the peer,
                if required by the protocol, is performed. Orderly
                termination leaves both peers with a consistent view of
                the world.</t>
           </list>
        </t>

        <section title="Forceful termination">
          <t>To perform forceful termination protocol descriptor is closed by
             hclose() function. In kernel-space implementations this function
             maps directly to standard POSIX close() function. The protocol MUST
             shut down immediately without trying to do termination handshake.
             Note that this is different from how classic BSD sockets behave.
             </t>
          <t>The protocol MUST also clean up all resources it owns including
             closing the underlying protocol. Given that the underlying protocol
             does the same operation, an entire stack of protocols can be shut
             down recursivelly by closing the file descriptor of the topmost
             protocol:</t>
          <figure>
            <artwork>
    int h1 = foo_start();
    int h2 = bar_start(h1);
    int h3 = baz_start(h2);
    hclose(h3); /* baz, bar and foo are shut down */
            </artwork>
          </figure>
          <t>In case of success hclose() returns zero. In case of error it
             returns -1 and sets errno to appropriate value.</t>
        </section>

        <section title="Half-close termination">
          <t>The primary use case for half-closing a connection is when user
             wants to close a connection, yet still wants to receive all the
             data sent by the peer prior to the termination.</t>
          <t>To do so function hdone() is used. It is roughly equivalent to
             POSIX shutdown(SHUT_WR) function.</t>
          <t>hdone() first of all flushes any buffered outbound data. What
             happens next depends on whether the protocol is connected or
             unconnected.</t>
          <t>For unconnected protocols the implementation MUST forward the call
             to the underlying socket. If the protocol is at the bottom of the
             stack and there is no underlying socket it MUST return
             ENOTSUP error.</t>
          <t>For connected protocols the implementation MUST start termination
             handshake and return to the caller without waiting for the answer
             from the peer.</t>
          <t>After hdone() is called, any further calls to hdone() or attemps
             to send more data MUST result in EPIPE error.</t>
          <t>However, user is still able to receive more data from the socket.
             </t>
           <t>Following piece of code shows typical usage do hdone(). It
              half-closes the connection, receives any pending messages from
              the peer and finally closes the socket:</t>
          <figure>
            <artwork>
    hdone(s);
    while(1) {
        int rc = mrecv(s, &amp;msg, sizeof(msg), -1);
        if(rc &lt; 0 &amp;&amp; errno == EPIPE) break;
        process_msg(&amp;msg); 
    }
    hclose(s);
            </artwork>
          </figure>
          <t>hdone() function returns 0 on success. In case of error the
             function MUST forcibly close the underying protocol (and thus
             recursively all protocols beneath it), return -1 and set errno to
             the appropriate value.</t>
        </section>

        <section title="Orderly termination">
          <t>To perform an orderly shut down there SHOULD be a protocol-specific
             function called "stop" (e.g. "smtp_stop").</t>
          <t>In addition to the file descriptor the function can have arbitrary
             number of other arguments. For example, one such argument may be a
             "shutdown reason" string to be sent to the peer. However, it is
             RECOMMENDED to avoid such additional arguments in newly designed
             protocols. The reason is that such arguments cannot be passed to
             hdone() function, making half-close termination functionally
             inferior to orderly termination.</t>
          <t>If the shut down functionality is potentially blocking the last
             argument of the function SHOULD be a deadline.</t>
          <t>First thing hclose() should do is to check whether hdone() was
             called by the user beforehand and if not so, to invoke it itself.
             </t>
          <t>If hdone() returns error other than ENOTSUP the socket MUST be
             torn down and the error MUST be forwarded to the caller.</t>
          <t>If hdone() returns ENOTSUP error the implementation MUST simply
             procceed further without reading any messages from the peer.</t>
          <t>If hdone() succeeds the implementation must read and drop any
             pending messages from the peer. Note that there is a possible DoS
             attack here: The peer can send infinite number of messages.
             Therefore, the implementation MUST observe the deadline and tear
             down the socket in case it runs out of time. ETIMEDOUT error is
             then returned to the user.</t>
          <t>At this point the implementation should deallocate the socket.
             However, it SHOULD NOT close the underlying protocol. Instead it
             SHOULD return its file descriptor to the user. This is crucial for
             horizontal composability of the protocols:</t>
          <figure>
            <artwork>
    /* create stack of two protocols */
    h1 = foo_start();
    h2 = bar_start(h1);
    /* top protocol is closed but bottom one is still alive */
    h1 = bar_stop(h2, -1);
    /* new top protocol is started */
    h3 = baz_start(h1);
    /* shut down both protocols */
    h1 = baz_stop(h3, -1);
    foo_stop(h1, -1);
            </artwork>
          </figure>
          <t>If protocol lives at the very bottom of the stack and has no
             underlying protocol "stop" function MUST return 0 on success.</t>
          <t>In the case of error stop function MUST forcibly close the
             underying protocol (and thus recursively all protocols beneath it),
             return -1 and set errno to the appropriate value.</t>
          <t>Note that this design of orderly termination does away with BSD
             socket SO_LINGER behaviour, which is problematic as it cannot be
             implemented cleanly in user space.</t>
        </section>

      </section>

      <section title="Normal operation">
        <t>Everything that happens between protocol initialization and protocol
           termination will be referred to as "normal operation".</t>
        <t>As already mentioned, application protocols can't send or receive
           data. Trying to invoke any of the functions below on an application
           protocol MUST result in ENOTSUP error.</t>
        <t>Transport protocols are either bystestream protocols or message
           protocols.</t>

          <section title="Bytestream protocols">
            <t>Bytestream protocols can be used via following four functions:
               </t>
            <figure>
              <artwork>
    int bsend(int h, const void *buf, size_t len,
        int64_t deadline);
    int brecv(int h, void *buf, size_t len,
        int64_t deadline);
    int bsendv(int h, const struct iovec *iov, size_t iovlen,
        int64_t deadline);
    int brecvv(int h, const struct iovec *iov, size_t iovlen,
        int64_t deadline);
              </artwork>
            </figure>
            <t>Function bsend() sends data to the protocol. The protocol SHOULD
               send them, after whatever manipulation is required, to its
               underlying protocol. Eventually, the bottommost protocol in the
               stack sends the data to the network.</t>
            <t>Function brecv() reads data from the protocol. The protocol
               SHOULD read them from the underlying socket and after whetever
               required manipulation is done return them to the caller.
               The bottommost protocol in the stack reads the data from the
               network.</t>
            <t>All the functions above MUST be blocking and exhibit atomic
               behaviour. I.e. either all data are sent/received or none of them
               are. In the later case protocol MUST be marked as broken, errno
               MUST be set to appropriate value and -1 MUST be returned to the
               user. Any subsequent attempt to use the protocol MUST result in
               an error.</t>
            <t>Expired deadline is considered to be an error and the protocol
               MUST behave as described above and set errno to ETIMEDOUT.</t>
            <t>In case of success all the functions MUST return zero.</t>
            <t>Functions bsendv() and brecvv() MUST behave in the same way
               as bsend() and brecv(), the only difference being that buffers
               are passed to the functions via scatter/gather arrays, same way
               as in POSIX sendmsg() and recvmsg() functions.</t>
            <t>Note that the implementations of brecv() and brecvv() MAY change
               the content of the buffer supplied to the function even in the
               case of error. However, what exaclty will be written into the
               buffer is unpredictable and using such data will result in
               undefined behaviour.</t>
          </section>

          <section title="Message protocols">
            <t>Message protocols can be used via following four functions:</t>
            <figure>
              <artwork>
    int msend(int s, const void *buf, size_t len,
        int64_t deadline);
    ssize_t mrecv(int h, void *buf, size_t len,
        int64_t deadline);
    int msendv(int s, const struct iovec *iov, size_t iovlen,
        int64_t deadline);
    ssize_t mrecvv(int s, const struct iovec *iov, size_t iovlen,
        int64_t deadline);
              </artwork>
            </figure>
            <t>Function msend() sends message to the protocol. The protocol
               SHOULD send it, after whatever manipulation is required, to its
               underlying protocol. Eventually, the lowermost protocol in the
               stack sends the data to the network.</t>
            <t>Function mrecv() reads message from the protocol. The protocol
               SHOULD read it from its underlying protocol and after whetever
               manipulation is needed return it to the caller. The lowermost
               protocol in the stack reads the data from the network.</t>
            <t>All the functions MUST be blocking and exhibit atomic behaviour.
               I.e. either entire message is sent/received or none of it is. In
               the later case errno MUST be set to appropriate value and -1 MUST
               be returned to the user. The protocol may be recoverable in
               which case receiving next message after an error is possible.
               In can also be non-recoverable in which the protocol MUST be
               marked as broken and any subsequent attempt to use it MUST result
               in an error.</t>
            <t>Note that unlike with bytestream sockets the buffer supplied to
               mrecv() doesn't have to be fully filled in, i.e. received
               messages may be smaller than the buffer.</t>
            <t>If the message is larger than the buffer, it is considered to be
               an error and the protocol must return -1 and set errno to
               EMSGSIZE. If there's no way to discard the unread part of
               the message in constant time it SHOULD also mark the protocol as
               broken and refuse any further operations. This behaviour prevents
               DoS attacks by sending very large messages.</t>
            <t>Expired deadline is considered to be an error and the protocol
               MUST return ETIMEDOUT error.</t>
            <t>In case of success msend() function MUST return zero, mrecv()
               MUST return the size of the received message, zero being a valid
               size.</t>
            <t>Functions msendv() and mrecvv() MUST behave in the same way
               as msend() and mrecv(). The only difference is that buffers are
               passed to the functions via scatter/gather arrays, same way as in
               POSIX sendmsg() and recvmsg() functions.</t>
            <t>Note that the implementations of mrecv() and mrecvv() MAY change
               the content of the buffer supplied to the function even in the
               case of error. However, what exaclty will be written into the
               buffer is unpredictable and using such data will result in
               undefined behaviour.</t>
          </section>

          <section title="Custom sending and receiving functions">
            <t>In addition to send/recv functions described above, protocols
               MAY implement their own custom send/recv functions. These
               functions should be called "send" and/or "recv" (e.g.
               "udp_send").</t>
            <t>Custom functions allow for providing additional arguments. For
               example, UDP protocol may implement custom send function with
               additional "destination IP address" argument.</t>
            <t>A protocol MAY implement multiple send or receive functions
               as needed.</t>
            <t>Protocol implementors should try to make custom send/recv
               functions as consistent with standard send/recv as possible.</t>
            <t>Standard send/recv functions SHOULD fill in arguments otherwise
               provided in custom send/recv by sensible defaults. It MAY be
               possible to set those defaults via "start" function.</t>
          </section>

          <section title="Error codes">
            <t>Send and receive function may return following error codes:
              <list style="symbols">
                <t>EBADF: Bad file descriptor.</t>
                <t>ECONNRESET: Connection broken. For example, a failure to
                   receive a keepalive from the peer may result in this error.
                   </t>
                <t>EMSGSIZE: Message is too large to fit into the supplied
                   buffer. Applies only to mrecv() and mrecvv().</t>
                <t>ENOTSUP: The socket does not support the function. For
                   example, msend() was called on a bytestream socket or mrecv()
                   was called on send-only socket.</t>
                <t>EPIPE: The peer have closed the connection.</t>
                <t>EPROTO: The peer has violated the protocol specification.</t>
                <t>ETIMEDOUT: Deadline expired.</t>
              </list>
            </t>
            <t>As already mentioned some protocols MAY treat errors as
               unrecoverable. In these cases any subsequent operation on the
               socket MUST return the same error.</t>
            <t>The implementation SHOULD NOT go into great lengths to implement
               recoverable errors. Instead, it should stick to the most natural
               semantics for the protocol. For example, EMSGSIZE may seem to be
               a recoverable error, however, the implementation may have to
               allocate arbitrary amount of memory to temporarily store the
               already received part of the message which could in turn enable
               DoS attacks by sending large messages. It may thus be
               preferable to keep these errors unrecoverable.</t>
          </section>

      </section>

    </section>

    <section title="Examples">
      <t>To give an example of microprotocols that can be implemented using
         proposed API, here's the list of what's implemented in the
         proof-of-concept project:
        <list style="sybmols">
          <t>compressor: compresses messages</t>
          <t>crlf: takes a bytestream protocol and turns it into message
             protocol by delimiting message by CRLF sequences</t>
          <t>encryptor: encrypts and authenticates messages</t>
          <t>keepalive: sends a keepalive message once in a while, on receiving
             side it check whether keepalives are arriving</t>
          <t>log: logs all data to the console (used for debugging)</t>
          <t>nagle: batches outgoing data to improve performance</t>
          <t>pfx: turns a bytestream protocol into message-based protocol by
             prefixing each message by its size</t>
          <t>tcp: wraps system implementation of TCP protocol</t>
          <t>throttler: imposes a limit of amount of data that can be sent
             and/or recevied per second</t>
          <t>udp: wraps system implementation of UDP protocol</t>
          <t>unix: wraps system implementation of UNIX domain sockets</t>
        </list>
      </t>
      <t>And here's an example of how the microprotocols can be combined to
         achieve complex functionality:</t>
      <figure>
        <artwork>
    /* Create a TCP connection. */
    h1 = tcp_connect(addr, -1);
    /* Limits outgoing traffic to 1MB/sec. Check every 1000ms. */
    h2 = throttler_start(h1, 1024 * 1024, 1000, 0, 0);
    /* Batch up to 2000 bytes of outgoing traffic. */
    h3 = nagle_start(h2, 2000, 100);
    /* Convert bytes into messages. */
    h4 = pfx_start(h3);
    /* Send keepalives message every 1000ms. */
    h5 = keepalive_start(h4, 1000, 4000, "KEEPALIVE", 9);
    /* Encrypt and authenticate messages. */
    h6 = encrypt_start(h5, key, sizeof(key), -1);
    /* Compress the messages. */
    h7 = compress_start(h6);
        </artwork>
      </figure>
      <t>Let's have a look at what happens to a message sent by the end user.
         It traverses the stack from level 7 to level 1. First it gets
         compressed, then it gets encrypted. Keepalive protocol doesn't modify
         the message but may interject keepalive messages. Then the message is
         transformed to a stream of bytes. In this case it's the size
         of the message in network byte order followed by the body
         of the message. Nagle protocol doesn't modify the data but it may
         delay it by at most 100ms and batch it with preceding and/or
         following data. Throttler once again doesn't modify the data but may
         delay it so as not to violate the bandwidth limit. Finally, the data is
         sent to the network via TCP protocol.</t>
      <t>In the opposite direction, message traverses the stack from level 1 to
         level 7. Bytes are read from TCP protocol. Throttler doesn't have
         limit set for incoming data and thus the data are just silently
         passed through it. Nagle doesn't do anything with incoming data.
         Then, the bytes are parsed and converted into a message. Keepalive
         layer doesn't do anything with the message itself, but it checks
         whether there have been any messages in last 4 seconds and if not so
         it raises an error. Finally, message is decrypted and authenticated at
         level 6 and decompressed at level 7.</t>
    </section>

    <section anchor="IANA" title="IANA Considerations">
      <t>This memo includes no request to IANA.</t>
    </section>

    <section anchor="Security" title="Security Considerations">
      <t>This memo addresses possible DoS attack at several places.</t>
      <t>Other than that, the security implications of the new API don't differ
         from security implications of classic BSD socket API. Still, it may be
         worth passing the design through a security audit.</t>
    </section>

  </middle>

</rfc>
